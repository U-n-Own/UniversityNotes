{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A comparison of Embedding space in Self-Supervised method and Supervised method\n",
    "\n",
    "Each type of neural network has it's own way to embed the input data into another high-dimensional space. In this notebook i'll show a comparison on how different Self-Supervised methods we saw during the course and Supervised Method embed their data and we will measure the goodness of those embeddings by applying some data mining technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import *\n",
    "from networks import SimpleCNN, SiameseNetwork\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# import mnist from torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda to go faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletDataset:\n",
    "\n",
    "    def __init__(self, mnist_dataset):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        self.classes = list(set(mnist_dataset.targets.numpy()))\n",
    "        self.class_to_images = {c: [] for c in self.classes}\n",
    "        \n",
    "        # Group images by class\n",
    "        for i in range(len(mnist_dataset)):\n",
    "            image, label = mnist_dataset[i]\n",
    "            self.class_to_images[label].append(image)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        anchor_image, anchor_label = self.mnist_dataset[index]\n",
    "        \n",
    "        # Select positive image from the same class\n",
    "        positive_image = random.choice(self.class_to_images[anchor_label])\n",
    "        \n",
    "        # Select negative image from a different class\n",
    "        negative_label = random.choice([c for c in self.classes if c != anchor_label])\n",
    "        negative_image = random.choice(self.class_to_images[negative_label])\n",
    "        \n",
    "        return anchor_image, positive_image, negative_image\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)\n",
    "    \n",
    "class SiameseMNIST:\n",
    "    \n",
    "    def __init__(self, mnist_dataset):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img1, label1 = self.mnist_dataset[index]\n",
    "        should_get_same_class = np.random.randint(0, 2)\n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                index2 = np.random.randint(0, len(self.mnist_dataset))\n",
    "                img2, label2 = self.mnist_dataset[index2]\n",
    "                if label1 == label2:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                index2 = np.random.randint(0, len(self.mnist_dataset))\n",
    "                img2, label2 = self.mnist_dataset[index2]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "        return (img1, img2), torch.tensor(int(label1 != label2), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and loading dataset\n",
    "mnist = datasets.MNIST('./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "triplet_dataset = TripletDataset(mnist)\n",
    "triplet_loader = torch.utils.data.DataLoader(triplet_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a forward pass and print shapes\n",
    "# networks are defined in networks.py in classes SimpleCNN and SiameseNetwork\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# taking a random sample from the dataset, we should get a tensor of shape [1, 32]\n",
    "sample =  mnist[random.choice(range(len(mnist)))]\n",
    "print(model.forward_once(sample[0].unsqueeze(0).to(device)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(triplet_loader))\n",
    "print(sample[0].shape, sample[1].shape, sample[2].shape)\n",
    "\n",
    "# plot with matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(sample[0][0].squeeze(), cmap='gray')\n",
    "axs[1].imshow(sample[1][0].squeeze(), cmap='gray')\n",
    "axs[2].imshow(sample[2][0].squeeze(), cmap='gray')\n",
    "\n",
    "# put legend \n",
    "axs[0].set_title('Anchor')\n",
    "axs[1].set_title('Positive')\n",
    "axs[2].set_title('Negative')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First experiment: Extracting feature from Triplet Loss trained model\n",
    "\n",
    "- Triplet Loss takes 3 images\n",
    "  - Anchor\n",
    "  - Positive\n",
    "  - Negative\n",
    "\n",
    "- The model is trained to minimize the distance between Anchor and Positive and maximize the distance between Anchor and Negative.\n",
    "\n",
    "$$\n",
    "\\mathcal{L(x, x^+, x^-)} = \\sum_{i=1}^{N} \\max(0, ||f(x_i) - f(x_i^+)||^2 - ||f(x_i) - f(x_i^-)||^2 + \\epsilon)\n",
    "$$\n",
    "\n",
    "Ideally we want to use hard samples, so those that are hard negative or hard positive. So sampling matters if we want better performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for checkpoint\n",
    "if os.path.exists('tripletmodel.pth'):\n",
    "    tripletmodel = SimpleCNN()\n",
    "    tripletmodel.load_state_dict(torch.load('tripletmodel.pth'))\n",
    "    tripletmodel.eval()\n",
    "    tripletmodel.to(device)\n",
    "    print('Model loaded')\n",
    "else:\n",
    "        \n",
    "    tripletmodel = SimpleCNN()\n",
    "    tripletloss = TripletLoss()\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(tripletmodel.parameters(), lr=1e-3)\n",
    "\n",
    "    tripletmodel.to(device)\n",
    "    triplet_train_loss = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "        pbar = tqdm(triplet_loader)\n",
    "        epoch_loss = 0\n",
    "        for anchor, positive, negative in pbar:\n",
    "\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            anchor_embedding = tripletmodel.forward_once(anchor)\n",
    "            positive_embedding = tripletmodel.forward_once(positive)\n",
    "            negative_embedding = tripletmodel.forward_once(negative)\n",
    "            \n",
    "            loss = tripletloss(anchor_embedding, positive_embedding, negative_embedding)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix_str(f'Loss {loss.item()}')\n",
    "            triplet_train_loss.append(loss.item())\n",
    "            \n",
    "        print(f'Epoch {epoch}, Loss {epoch_loss/len(triplet_loader)}')\n",
    "\n",
    "        \n",
    "    # Save the model\n",
    "    torch.save(tripletmodel.state_dict(), 'tripletmodel.pth')\n",
    "    # save the loss\n",
    "    np.save('triplet_train_loss.npy', triplet_train_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripletmodel.eval()\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "#take the first 1000 images\n",
    "for i in range(5000):\n",
    "    image, label = mnist[i]\n",
    "\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    embedding = tripletmodel.forward_once(image)\n",
    "    labels.append(label)\n",
    "    embeddings.append(embedding.cpu().detach().numpy())\n",
    "\n",
    "embeddings_triplet = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "\n",
    "# ogni colonna del dataframe è una dimensione dell'embedding (x0, x1, x2, ..., x31) e l'ultima colonna è la label\n",
    "df = pd.DataFrame(embeddings_triplet, columns=[f'x{i}' for i in range(embeddings_triplet.shape[1])])\n",
    "df['label'] = labels\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pca and plot\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_embeddings_triplet = pca.fit_transform(embeddings_triplet)\n",
    "\n",
    "df['pca1'] = pca_embeddings_triplet[:, 0]\n",
    "df['pca2'] = pca_embeddings_triplet[:, 1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=df, x='pca1', y='pca2', hue='label', palette='tab10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network \n",
    "\n",
    "- Siamese Network takes 2 images and works similarly to Triplet Loss, but it's trained to minimize the distance between the two images.\n",
    "\n",
    "- Runs two forward passes on the same network with the same weights on the images\n",
    "- Apply the following loss function:\n",
    "\n",
    "First compute a distance, can be L1 or L2 thats is differentiable (also cosine works) + linear ffw and nonlinearity ($\\sigma$) to get a probability\n",
    "$$\n",
    "p(x_i, x_j) = \\sigma(W |f(x_i) - f(x_j)|)\n",
    "$$\n",
    "\n",
    "Of course the loss will be on a Batch : $\\mathcal{L}(B)$ but on two sample is something like:\n",
    "$$\n",
    "\\mathcal{L(x_i, x_j)} = \\mathbb{1}_{y_i = y_j} \\log(p(x_i, x_j)) + \\mathbb{1}_{y_i \\neq y_j} \\log(1 - p(x_i, x_j)) \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = datasets.MNIST('./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "siamese_dataset = SiameseMNIST(mnist)\n",
    "\n",
    "siamese_loader = torch.utils.data.DataLoader(siamese_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(siamese_loader))\n",
    "\n",
    "# show both positive and negative pair\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(sample[0][0][0].squeeze(), cmap='gray')\n",
    "axs[1].imshow(sample[0][1][0].squeeze(), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for checkpoint\n",
    "if os.path.exists('siamese_network.pth'):\n",
    "    siamese_network = SiameseNetwork()\n",
    "    siamese_network.load_state_dict(torch.load('siamese_network.pth'))\n",
    "    siamese_network.eval()\n",
    "    siamese_network.to(device)\n",
    "    print('Model loaded')\n",
    "else:\n",
    "\n",
    "    siamese_network = SiameseNetwork()\n",
    "    siamese_network.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(siamese_network.parameters(), lr=1e-3)\n",
    "\n",
    "    contrastive_loss = ContrastiveLoss()\n",
    "\n",
    "    siamese_train_loss = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "        \n",
    "        pbar = tqdm(siamese_loader)\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for (img1, img2), target in pbar:\n",
    "            \n",
    "            img1 = img1.to(device)\n",
    "            img2 = img2.to(device)\n",
    "            #label\n",
    "            target = target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output1, output2 = siamese_network(img1, img2)\n",
    "            loss = contrastive_loss(output1, output2, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix_str(f'Loss {loss.item()}')\n",
    "            siamese_train_loss.append(loss.item())\n",
    "            \n",
    "        print(f'Epoch {epoch}, Loss {epoch_loss/len(siamese_loader)}')\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(siamese_network.state_dict(), 'siamese_network.pth')\n",
    "    # save the loss\n",
    "    np.save('siamese_train_loss.npy', siamese_train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network.eval()\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5000):\n",
    "    image, label = mnist[i]\n",
    "\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    #forward once\n",
    "    embedding = siamese_network(image, image)[0]\n",
    "    labels.append(label)\n",
    "    embeddings.append(embedding.cpu().detach().numpy())\n",
    "    \n",
    "    \n",
    "embeddings_siamese = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "df = pd.DataFrame(embeddings_siamese, columns=[f'x{i}' for i in range(embeddings_siamese.shape[1])])\n",
    "df['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca_embeddings_siamese = pca.fit_transform(embeddings_siamese)\n",
    "\n",
    "df['pca1'] = pca_embeddings_siamese[:, 0]\n",
    "df['pca2'] = pca_embeddings_siamese[:, 1]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=df, x='pca1', y='pca2', hue='label', palette='tab10')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline on Supervised Approach: SimpleCNN\n",
    "\n",
    "- We will train a simple CNN on the dataset and extract the features from the last layer before the classification layer.\n",
    "\n",
    "- The loss is the usual CrossEntropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just classic train of CNN on MNIST\n",
    "\n",
    "# check for checkpoint\n",
    "\n",
    "mnist = datasets.MNIST('./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist, batch_size=1024, shuffle=True)\n",
    "\n",
    "if os.path.exists('baseline_model.pth'):\n",
    "    model = SimpleCNN()\n",
    "    model.load_state_dict(torch.load('baseline_model.pth'))\n",
    "    baseline_train_loss = np.load('baseline_train_loss.npy')\n",
    "else:\n",
    "\n",
    "    model = SimpleCNN().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    baseline_train_loss = []\n",
    "\n",
    "    # send to device\n",
    "    for epoch in range(10):\n",
    "        pbar = tqdm(mnist_loader)\n",
    "        epoch_loss = 0\n",
    "        for image, label in pbar:\n",
    "\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model.forward_once(image)\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix_str(f'Loss {loss.item()}')\n",
    "            baseline_train_loss.append(loss.item())\n",
    "\n",
    "        print(f'Epoch {epoch}, Loss {epoch_loss/len(mnist_loader)}')\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'baseline_model.pth')\n",
    "    # save the loss\n",
    "    np.save('baseline_train_loss.npy', baseline_train_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5000):\n",
    "    image, label = mnist[i]\n",
    "\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    embedding = model.forward_once(image)\n",
    "    labels.append(label)\n",
    "    embeddings.append(embedding.cpu().detach().numpy())\n",
    "    \n",
    "embeddings_baseline = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "df = pd.DataFrame(embeddings_baseline, columns=[f'x{i}' for i in range(embeddings_baseline.shape[1])])\n",
    "df['label'] = labels\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca_embeddings_baseline = pca.fit_transform(embeddings_baseline)\n",
    "\n",
    "df['pca1'] = pca_embeddings_baseline[:, 0]\n",
    "df['pca2'] = pca_embeddings_baseline[:, 1]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=df, x='pca1', y='pca2', hue='label', palette='tab10')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating goodness of clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use a data mining approach like silhouette score to evaluate the quality of the clustering\n",
    "# So we can compare different Losses: TripletLoss, ContrastiveLoss, SiameseLoss and SupervisedApproach\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "triplet_score = silhouette_score(embeddings_triplet, labels)\n",
    "print(f'Triplet Loss Silhouette Score: {triplet_score}')\n",
    "\n",
    "siamese_score = silhouette_score(embeddings_siamese, labels)   \n",
    "print(f'Siamese Loss Silhouette Score: {siamese_score}')\n",
    "\n",
    "baseline_score = silhouette_score(embeddings_baseline, labels)\n",
    "print(f'Baseline Silhouette Score: {baseline_score}')\n",
    "\n",
    "\n",
    "# Bar chart order by silhouette score\n",
    "scores = [siamese_score, triplet_score, baseline_score]\n",
    "\n",
    "plt.bar(['Siamese', 'Triplet', 'Baseline'], scores)\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Losses to visualize convergence of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Ensure this import is correct\n",
    "\n",
    "# plotting the losses\n",
    "# add some alpha to the plot\n",
    "plt.plot(triplet_train_loss, label='Triplet Loss', alpha=0.75)\n",
    "plt.plot(siamese_train_loss, label='Siamese (Contrastive Loss)', alpha=0.75)\n",
    "plt.plot(baseline_train_loss, label='Baseline', alpha=0.75)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting on FashionMNIST\n",
    "\n",
    "- We will use the FashionMNIST dataset to train the models and extract the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = datasets.FashionMNIST('./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "triplet_dataset = TripletDataset(fashion_mnist)\n",
    "triplet_loader = torch.utils.data.DataLoader(triplet_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample\n",
    "sample = next(iter(triplet_loader))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(sample[0][0].squeeze(), cmap='gray')\n",
    "axs[1].imshow(sample[1][0].squeeze(), cmap='gray')\n",
    "axs[2].imshow(sample[2][0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('triplet_fashion_model.pth'):\n",
    "    tripletmodel = SimpleCNN()\n",
    "    tripletmodel.load_state_dict(torch.load('triplet_fashion_model.pth'))\n",
    "    tripletmodel.eval()\n",
    "    tripletmodel.to(device)\n",
    "    print('Model loaded')\n",
    "else:\n",
    "\n",
    "    tripletmodel = SimpleCNN()\n",
    "    tripletloss = TripletLoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(tripletmodel.parameters(), lr=1e-3)\n",
    "\n",
    "    tripletmodel.to(device)\n",
    "    triplet_train_loss = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "        pbar = tqdm(triplet_loader)\n",
    "        epoch_loss = 0\n",
    "        for anchor, positive, negative in pbar:\n",
    "\n",
    "            anchor = anchor.to(device)\n",
    "            positive = positive.to(device)\n",
    "            negative = negative.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            anchor_embedding = tripletmodel.forward_once(anchor)\n",
    "            positive_embedding = tripletmodel.forward_once(positive)\n",
    "            negative_embedding = tripletmodel.forward_once(negative)\n",
    "            \n",
    "            loss = tripletloss(anchor_embedding, positive_embedding, negative_embedding)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix_str(f'Loss {loss.item()}')\n",
    "            triplet_train_loss.append(loss.item())\n",
    "            \n",
    "        print(f'Epoch {epoch}, Loss {epoch_loss/len(triplet_loader)}')\n",
    "\n",
    "    # Save the model\n",
    "    torch.save(tripletmodel.state_dict(), 'triplet_fashion_model.pth')\n",
    "    # save the loss\n",
    "    np.save('triplet_fashion_train_loss.npy', triplet_train_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tripletmodel.eval()\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5000):\n",
    "    image, label = fashion_mnist[i]\n",
    "\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    embedding = tripletmodel.forward_once(image)\n",
    "    labels.append(label)\n",
    "    embeddings.append(embedding.cpu().detach().numpy())\n",
    "    \n",
    "embeddings_triplet_fashion = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "df = pd.DataFrame(embeddings_triplet_fashion, columns=[f'x{i}' for i in range(embeddings_triplet_fashion.shape[1])])\n",
    "df['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca_embeddings_triplet_fashion = pca.fit_transform(embeddings_triplet_fashion)\n",
    "\n",
    "df['pca1'] = pca_embeddings_triplet_fashion[:, 0]\n",
    "df['pca2'] = pca_embeddings_triplet_fashion[:, 1]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=df, x='pca1', y='pca2', hue='label', palette='tab10')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fascion_mnist = datasets.FashionMNIST('./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "siamese_dataset = SiameseMNIST(fashion_mnist)\n",
    "\n",
    "siamese_loader = torch.utils.data.DataLoader(siamese_dataset, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample\n",
    "sample = next(iter(siamese_loader))\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow(sample[0][0][0].squeeze(), cmap='gray')\n",
    "axs[1].imshow(sample[0][1][0].squeeze(), cmap='gray')\n",
    "\n",
    "# label 1 or 0 if the images are similar or not\n",
    "label = sample[1][0].item()\n",
    "print(f'Target: {label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripletmodel.eval()\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "#take the first 1000 images\n",
    "for i in range(5000):\n",
    "    image, label = mnist[i]\n",
    "\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    embedding = tripletmodel.forward_once(image)\n",
    "    labels.append(label)\n",
    "    embeddings.append(embedding.cpu().detach().numpy())\n",
    "\n",
    "embeddings_triplet = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "\n",
    "# ogni colonna del dataframe è una dimensione dell'embedding (x0, x1, x2, ..., x31) e l'ultima colonna è la label\n",
    "df = pd.DataFrame(embeddings_triplet, columns=[f'x{i}' for i in range(embeddings_triplet.shape[1])])\n",
    "df['label'] = labels\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('siamese_fashion_network.pth'):\n",
    "    siamese_network = SiameseNetwork()\n",
    "    siamese_network.load_state_dict(torch.load('siamese_fashion_network.pth'))\n",
    "    siamese_network.eval()\n",
    "    siamese_network.to(device)\n",
    "    print('Model loaded')\n",
    "else:\n",
    "        \n",
    "\n",
    "    siamese_network = SiameseNetwork()\n",
    "\n",
    "    siamese_network.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(siamese_network.parameters(), lr=1e-3)\n",
    "\n",
    "    contrastive_loss = ContrastiveLoss()\n",
    "\n",
    "    siamese_train_loss = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "            \n",
    "            pbar = tqdm(siamese_loader)\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            for (img1, img2), target in pbar:\n",
    "                \n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                target = target.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output1, output2 = siamese_network(img1, img2)\n",
    "                loss = contrastive_loss(output1, output2, target)\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                pbar.set_postfix_str(f'Loss {loss.item()}')\n",
    "                siamese_train_loss.append(loss.item())\n",
    "                \n",
    "            print(f'Epoch {epoch}, Loss {epoch_loss/len(siamese_loader)}')\n",
    "            \n",
    "    # Save the model\n",
    "    torch.save(siamese_network.state_dict(), 'siamese_fashion_network.pth')\n",
    "    # save the loss\n",
    "    np.save('siamese_fashion_train_loss.npy', siamese_train_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network.eval()\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5000):\n",
    "    image, label = fashion_mnist[i]\n",
    "\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    embedding = siamese_network(image, image)[0]\n",
    "    labels.append(label)\n",
    "    embeddings.append(embedding.cpu().detach().numpy())\n",
    "    \n",
    "embeddings_siamese_fashion = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "df = pd.DataFrame(embeddings_siamese_fashion, columns=[f'x{i}' for i in range(embeddings_siamese_fashion.shape[1])])\n",
    "df['label'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca_embeddings_siamese_fashion = pca.fit_transform(embeddings_siamese_fashion)\n",
    "\n",
    "df['pca1'] = pca_embeddings_siamese_fashion[:, 0]\n",
    "df['pca2'] = pca_embeddings_siamese_fashion[:, 1]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=df, x='pca1', y='pca2', hue='label', palette='tab10')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = datasets.FashionMNIST('./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "mnist_loader = torch.utils.data.DataLoader(fashion_mnist, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('baseline_fashion_model.pth'):\n",
    "    model = SimpleCNN()\n",
    "    model.load_state_dict(torch.load('baseline_fashion_model.pth'))\n",
    "    baseline_train_loss = np.load('baseline_fashion_train_loss.npy')\n",
    "else:\n",
    "\n",
    "        \n",
    "    model = SimpleCNN().to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    baseline_train_loss = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "        pbar = tqdm(mnist_loader)\n",
    "        epoch_loss = 0\n",
    "        for image, label in pbar:\n",
    "\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model.forward_once(image)\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            pbar.set_postfix_str(f'Loss {loss.item()}')\n",
    "            baseline_train_loss.append(loss.item())\n",
    "\n",
    "        print(f'Epoch {epoch}, Loss {epoch_loss/len(mnist_loader)}')\n",
    "        \n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), 'baseline_fashion_model.pth')\n",
    "    # save the loss\n",
    "    np.save('baseline_fashion_train_loss.npy', baseline_train_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for i in range(5000):\n",
    "    image, label = fashion_mnist[i]\n",
    "\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    embedding = model.forward_once(image)\n",
    "    labels.append(label)\n",
    "    embeddings.append(embedding.cpu().detach().numpy())\n",
    "    \n",
    "embeddings_baseline_fashion = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "df = pd.DataFrame(embeddings_baseline_fashion, columns=[f'x{i}' for i in range(embeddings_baseline_fashion.shape[1])])\n",
    "df['label'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "pca_embeddings_baseline_fashion = pca.fit_transform(embeddings_baseline_fashion)\n",
    "\n",
    "df['pca1'] = pca_embeddings_baseline_fashion[:, 0]\n",
    "df['pca2'] = pca_embeddings_baseline_fashion[:, 1]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(data=df, x='pca1', y='pca2', hue='label', palette='tab10')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize embeddings scores on FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same silhouette score for the fashion mnist dataset\n",
    "\n",
    "triplet_score = silhouette_score(embeddings_triplet_fashion, labels)\n",
    "siamese_score = silhouette_score(embeddings_siamese_fashion, labels)\n",
    "baseline_score = silhouette_score(embeddings_baseline_fashion, labels)\n",
    "\n",
    "# Show bar chart\n",
    "scores = [siamese_score, triplet_score, baseline_score]\n",
    "\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another losses comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the losses\n",
    "plt.plot(triplet_train_loss, label='Triplet Loss', alpha=0.75)\n",
    "plt.plot(siamese_train_loss, label='Siamese (Contrastive Loss)', alpha=0.75)\n",
    "plt.plot(baseline_train_loss, label='Baseline', alpha=0.75)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is not an Apple to Apple comparison\n",
    "\n",
    "Since the models are train on different tasks the loss are not easy to compare. But what we can do is take the embeddings and apply a KNN on them and see how well they perform on a classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get all embeddings in a pd.DataFrame\n",
    "df_triplet = pd.DataFrame(embeddings_triplet, columns=[f'x{i}' for i in range(embeddings_triplet.shape[1])])\n",
    "df_triplet['label'] = labels\n",
    "\n",
    "df_siamese = pd.DataFrame(embeddings_siamese, columns=[f'x{i}' for i in range(embeddings_siamese.shape[1])])\n",
    "df_siamese['label'] = labels\n",
    "\n",
    "df_baseline = pd.DataFrame(embeddings_baseline, columns=[f'x{i}' for i in range(embeddings_baseline.shape[1])])\n",
    "df_baseline['label'] = labels\n",
    "\n",
    "# Split the data\n",
    "X_train_triplet, X_test_triplet, y_train_triplet, y_test_triplet = train_test_split(df_triplet.drop(columns='label'), df_triplet['label'], test_size=0.2)\n",
    "X_train_siamese, X_test_siamese, y_train_siamese, y_test_siamese = train_test_split(df_siamese.drop(columns='label'), df_siamese['label'], test_size=0.2)\n",
    "X_train_baseline, X_test_baseline, y_train_baseline, y_test_baseline = train_test_split(df_baseline.drop(columns='label'), df_baseline['label'], test_size=0.2)\n",
    "\n",
    "# Train the KNN\n",
    "\n",
    "knn_triplet = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_siamese = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_baseline = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn_triplet.fit(X_train_triplet, y_train_triplet)\n",
    "knn_siamese.fit(X_train_siamese, y_train_siamese)\n",
    "knn_baseline.fit(X_train_baseline, y_train_baseline)\n",
    "\n",
    "# Evaluate the KNN using elbow method\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_triplet = []\n",
    "accuracy_siamese = []\n",
    "accuracy_baseline = []\n",
    "\n",
    "for k in range(1, 20):\n",
    "    knn_triplet = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_siamese = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_baseline = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    knn_triplet.fit(X_train_triplet, y_train_triplet)\n",
    "    knn_siamese.fit(X_train_siamese, y_train_siamese)\n",
    "    knn_baseline.fit(X_train_baseline, y_train_baseline)\n",
    "\n",
    "    accuracy_triplet.append(accuracy_score(y_test_triplet, knn_triplet.predict(X_test_triplet)))\n",
    "    accuracy_siamese.append(accuracy_score(y_test_siamese, knn_siamese.predict(X_test_siamese)))\n",
    "    accuracy_baseline.append(accuracy_score(y_test_baseline, knn_baseline.predict(X_test_baseline)))\n",
    "    \n",
    "plt.plot(range(1, 20), accuracy_triplet, label='Triplet Loss', alpha=0.75)\n",
    "plt.plot(range(1, 20), accuracy_siamese, label='Siamese Loss', alpha=0.75)\n",
    "plt.plot(range(1, 20), accuracy_baseline, label='Baseline', alpha=0.75)\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('K')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
